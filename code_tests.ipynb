{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "vid_path = Path(\"/home/utku/Documents/raw_datasets/Traffic_sign_light_classification/VK_datasets/apems_vehicle_radar_tests/karagoz-recordings__220609_apems_vehicle_radar_tests__apems_vehicle_old_frp_kampus/karagoz-recordings__220609_apems_vehicle_radar_tests__apems_vehicle_old_frp_kampus.mp4\")\n",
    "str_path = str(vid_path)\n",
    "ot_path = \"/home/utku/Documents/raw_datasets/Traffic_sign_light_classification/VK_datasets/apems_vehicle_radar_tests/karagoz-recordings__220609_apems_vehicle_radar_tests__apems_vehicle_old_frp_kampus/apems_vehicle_old_frp_kampus_2022-06-09-07-22-39_0_kdb_fn_compressed_short.mp4\"\n",
    "cap = cv2.VideoCapture(str_path)\n",
    "retval, frame = cap.read()\n",
    "print(retval)\n",
    "cv2.imshow(\"hey\", frame)\n",
    "cv2.waitKey(0)\n",
    "while cap.isOpened():\n",
    "    print(\"hey\")\n",
    "    retval, frame = cap.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "ar = numpy.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "for tt in ar.T:\n",
    "    print(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ap = Path(\"a/b/c.jpg\")\n",
    "ap.with_suffix(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import C_DICT, class_names, class_to_idx_dict\n",
    "from c_hmcnn_efficient_net import R_constraint_matrix, get_constr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "at = torch.tensor([True,False,True])\n",
    "bt = torch.tensor([1,0,1])\n",
    "sum(at==bt)\n",
    "torch.sum(torch.logical_and(at, bt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_eff_net = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
    "hier_classification_head = torch.nn.Linear(in_features = single_eff_net.classifier.fc.in_features, out_features =  19)\n",
    "single_eff_net.classifier.fc = hier_classification_head\n",
    "single_eff_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_eff_net = torchvision.models.regnet_x_16gf(pretrained=True)\n",
    "single_eff_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "single_eff_net = torchvision.models.efficientnet_b0(pretrained=True)# torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
    "single_eff_net.classifier[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = torch.tensor([1.0,1.0,0.0])\n",
    "ct == at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "c_out = torch.arange(19).reshape(19,1)\n",
    "c_out = c_out.expand(R_constraint_matrix.shape[1], R_constraint_matrix.shape[1], R_constraint_matrix.shape[1])\n",
    "out = c_out.to(\"cuda\")*R_constraint_matrix\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_constraint_matrix.expand(R_constraint_matrix.shape[1], R_constraint_matrix.shape[1], R_constraint_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = R_constraint_matrix[0,1,:] # dim=2 gives ancestors.\n",
    "C_REVERSED = {val: key for key,val in C_DICT.items()}\n",
    "for idx, a in enumerate(at):\n",
    "    if a.item() == 1:\n",
    "        print(idx, C_REVERSED[idx])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([10,5,0,0,0,0,0,0,15,4,0,0,0,5,0,0,0,0,0]).reshape(1,19)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_DICTNUMBER_OF_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_batch = torch.tensor([1,4,6,3,6,7,10]).unsqueeze(dim = 0)\n",
    "R_constraint_matrix[0, labels_batch, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_constr_out(x, R_constraint_matrix.transpose(1,2)) # You need descendants for the constraint output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "ap = Path(\"a/b/c/d\")\n",
    "print(ap.parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = [\"asdf\",\"casdfsd\",\"aaa\"]\n",
    "al.sort() # Is a modifier\n",
    "\n",
    "al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"test.log\"), \"w\") as writer:\n",
    "    writer.write(\"trash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"asdf\".capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = [4,2,5,2,1]\n",
    "en = list(enumerate(al))\n",
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "  \n",
    "# Read the image from computer\n",
    "input_img = Image.open('/home/utku/Documents/repos/dfas_classifier/data_ops/atis_yonelim_classification_dataset_combined_orig/all/dogrultmamis/cerkez_Cerkezkoy-1_Speedup_2_147_10.jpg')\n",
    "  \n",
    "# define a transform\n",
    "transform = transforms.GaussianBlur(kernel_size=5)\n",
    "transform= transforms.RandomPosterize(bits=6, p=0.2)\n",
    "transform = transforms.RandomAdjustSharpness(sharpness_factor=0.7, p=0.3)\n",
    "transform = transforms.RandomAutocontrast(p=0.3)\n",
    "transform = transforms.RandomEqualize(p=1)\n",
    "\n",
    "transform = transforms.RandomErasing(p=1, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0, inplace=False)\n",
    "output_img = transform(transforms.ToTensor()(input_img))\n",
    "img = transforms.ToPILImage()(output_img)\n",
    "img.show()\n",
    "# transform = transforms.RandomRotation(degrees=10)\n",
    "# transform = transforms.RandomPerspective(distortion_scale=0.3, p=0.3)\n",
    "  \n",
    "# apply the above transform on image\n",
    "# output_img = transform(input_img)\n",
    "  \n",
    "# display result\n",
    "output_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.load(\"/home/utku/Documents/repos/dfas_classifier/weights/byol_resnet-18_40-epochs_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a[\"encoder_state_dict\"].keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD BYOL RESNET 18 WEIGHTS FROM https://github.com/sthalles/PyTorch-BYOL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from typing import OrderedDict\n",
    "ResNet = torchvision.models.resnet18(pretrained=False)\n",
    "number_of_input_features = ResNet.fc.in_features\n",
    "NUMBER_OF_CLASSES = 10\n",
    "ResNet.fc = torch.nn.Identity()\n",
    "state_dict = torch.load(\"/home/utku/Documents/repos/dfas_classifier/weights/byol_resnet-18_40-epochs_model.pth\")[\"encoder_state_dict\"]\n",
    "target_state_dict = ResNet.state_dict().keys()\n",
    "correct_state_dict = OrderedDict()\n",
    "for (k, v), correct_state_dict_name in zip(state_dict.items(),target_state_dict):\n",
    "    correct_state_dict[correct_state_dict_name] = v\n",
    "ResNet.load_state_dict(correct_state_dict)\n",
    "ResNet.fc = torch.nn.Linear(number_of_input_features, NUMBER_OF_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ResNet.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
    "effnet2 = torchvision.models.efficientnet_b0()\n",
    "for (a,b), (c,d) in zip(effnet2.named_parameters(), model.named_parameters()):\n",
    "    print(a, \"\\t\", c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1484ded363958018b63f22e3cca0a4db1032bdb5172b1a076544307dcdefb374"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
